{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data:image/jpeg;base64,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)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification With MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "# When the script is run on the computer you need to download keras with anaconda \n",
    "# copy and paste this line in the terminal \n",
    "# conda install -c conda-forge keras \n",
    "# import warnings for unwanted warnings \n",
    "# These are all the imports that are needed \n",
    "from keras.datasets import mnist # dataset\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs)\n",
    "\n",
    "Convolutional Neural Networks are very similar to ordinary Neural Networks: they are made up of neurons that have learnable weights and biases. Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity. The whole network still expresses a single differentiable score function: from the raw image pixels on one end to class scores at the other. And they still have a loss function (e.g. SVM/Softmax) on the last (fully-connected) layer and all the tips/tricks we developed for learning regular Neural Networks still apply.\n",
    "\n",
    "So what changes? ConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network.\n",
    "\n",
    "![](http://cs231n.github.io/assets/nn1/neural_net2.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "The dataset is loaded into four variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "# X_train = training images \n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape # this prints out the shape of the training images \n",
    "\n",
    "# These are dimensions of the array [60000,23,28]\n",
    "# print(X_train.shape[0])#number of images \n",
    "# print(X_train.shape[1])#width\n",
    "# print(X_train.shape[2])#height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why reshape ?\n",
    "When the Data is loaded from mnist.load_data() the structure of the data is (60000,28,28) i.e images with 2 dimensions 28 x 28. \n",
    "\n",
    "The Convolution2D layers in Keras work with 4 dimensions (sample/batch, height, width, channels) i.e has 4 dimensions input and output but more importantly, it covers deeper layers of the network, where each example has become a set of feature maps i.e. (nb_samples, nb_features, width, height)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to format which CNN expects (batch, height, width, channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\" or \"transformation\"\n",
    "\n",
    "Each value is between 0-255 in the MNIST Dataset images. However, this would produce math range errors, So all value are divided by 255 to get decimal values between 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train/=255\n",
    "X_test/=255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "\n",
    "One-hot encoding means writing categorical variables in a one-hot vector format, where the vector is all-zero apart from one element. \n",
    "* For example if we are expecting output of 8 so according to one-hot coding its [0,0,0,0,0,0,0,0,1,0]\n",
    "* The index with a non zero value dictates which image label it is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#number of classes\n",
    "classes = 10\n",
    "# one-hot encoding\n",
    "# we are expecting output as 8 means value of output variable 8\n",
    "# so according to one-hot coding its [0,0,0,0,0,0,0,0,1,0]\n",
    "y_train = np_utils.to_categorical(y_train, classes)\n",
    "y_test = np_utils.to_categorical(y_test, classes)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create A Model \n",
    "The Sequential model is a linear stack of layers.You can create a Sequential model by passing a list of layer instances to the constructor\n",
    "The model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape. There are several possible ways to do this:\n",
    "\n",
    "- Pass an input_shape argument to the first layer. This is a shape tuple (a tuple of integers or None entries, where None indicates that any positive integer may be expected). In input_shape, the batch dimension is not included.\n",
    "- Some 2D layers, such as Dense, support the specification of their input shape via the argument input_dim, and some 3D temporal layers support the arguments input_dim and input_length.\n",
    "- If you ever need to specify a fixed batch size for your inputs (this is useful for stateful recurrent networks), you can pass a batch_size argument to a layer. If you pass both batch_size=32 and input_shape=(6, 8) to a layer, it will then expect every batch of inputs to have the batch shape (32, 6, 8).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "# 32 = convolution filters to use, 5 =rows in each convolution kernel,\n",
    "# and 5 = columns in each convolution kernel\n",
    "# input_shape = (depth, width, height)\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model\n",
    "Now that the model is in place we configure the learning process using .compile().\n",
    "Before training a model, you need to configure the learning process, which is done via the compile method. It receives three arguments:\n",
    "\n",
    "- An optimizer. This could be the string identifier of an existing optimizer (such as rmsprop or adagrad), or an instance of the Optimizer class.\n",
    "- A loss function. This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (such as categorical_crossentropy or mse), or it can be an objective function.\n",
    "- A list of metrics. For any classification problem you will want to set this to metrics=['accuracy']. A metric could be the string identifier of an existing metric or a custom metric function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model \n",
    "To fit the model, all we have to do is declare the batch size and number of epochs to train for, then pass in our training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 1476s 25ms/step - loss: 0.0809 - acc: 0.9756 - val_loss: 0.0476 - val_acc: 0.9843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2767a18cb70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model # im only doing 1 epoch because the time it takes to run 10 epochs is 5 to 6 hours on my machine\n",
    "# but i have ran it for 10 epochs and saved the data in h5 file \n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1, batch_size=200)\n",
    "# Save the model to use test the pictures for later\n",
    "# model.save('models/mnistModel.h5') #uncomment this to save the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics(Test loss & Test Accuracy): \n",
      "Test loss: 0.04762404235785361\n",
      "Test accuracy: 0.9843\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "score  = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Metrics(Test loss & Test Accuracy): \")\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The more epochs are run the better the accuracy gets. Atfer 10 epochs the accuracy increase is marginal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Saved Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import load_model\n",
    "model = load_model('models/mnistModel.h5')\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "import gzip\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make a folder which will store the the downloads\n",
    "path = 'data/'\n",
    "#initialise array\n",
    "ndArray = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the MNIST Test Files\n",
    "\n",
    "### Get the file url from [Data Set website](http://yann.lecun.com/exdb/mnist/) \n",
    "- First i will use the url \"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\" to download the files. \n",
    "- This has all the train images and test images plus the labels for both sets from the database.\n",
    "\n",
    "### The split method \n",
    "\"Method returns a list of strings after breaking the given string by the specified separator\"\n",
    "- I'm using the split method to get the last value which is the name of the file\n",
    "- Filename = url.split('/')[5] # i could do it this way or go to the last value like url.split('/')[-1]\n",
    "- By splitting the url I get the last value of the url http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz which is train-images-idx3-ubyte.gz and thats what I will name my file when i download it.\n",
    "\n",
    "### Download \n",
    "- Check if the file I am downloading already exists.\n",
    "- If it does then dont download the file \n",
    "- Else if it doesn't exists then download the file from url to a folder called data.\n",
    "\n",
    "##### Display all the files in the folder\n",
    "os.listdir('data')This gets all the files in the Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the file does not exist then make a new file \n",
    "# This makes sure that a file is made even when it doesnt exist\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# This is for the first option \n",
    "def DownloadFiles():\n",
    "        \n",
    "    # This will store all the rest of urls that i need to download\n",
    "    # The Test Images /Test Labels\n",
    "    urls = ['http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "            'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "    # We can go through a for loop and download the files\n",
    "    for url in urls:\n",
    "        # We can then split each url to just the file name \n",
    "        file = url.split('/')[-1]\n",
    "        # print(file)\n",
    "        \n",
    "        #Now in the for loop check if the file exists \n",
    "        #if the file that im downloading already exists\n",
    "        # Then it will not download it \n",
    "        if os.path.exists(path+file):\n",
    "            print('The File Youre trying to download already exists!', file)\n",
    "        else:\n",
    "            #if the file does not exist the it will download the file\n",
    "            print('The',file, 'Is Downloading')\n",
    "            urllib.request.urlretrieve (url, path+file)\n",
    "    print('Done Downloading')\n",
    "\n",
    "    # This here shows how many files exist in the directory\n",
    "    # It should have 2 different files in the folder \n",
    "    # get a list of all the files in the folder 'data'\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    #the for loop goes through each file and extracts it \n",
    "    for file in files:\n",
    "        #checks if the file ends in .gz \n",
    "        if file.endswith('.gz'):\n",
    "            #this reads the file with gzip \n",
    "            with gzip.open(path+file, 'rb') as In:\n",
    "            #removes the .gz file\n",
    "                with open(path+file.split('.')[0], 'wb') as out:\n",
    "                    #shutil copies the contents from In to out\n",
    "                    shutil.copyfileobj(In, out)\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith('.gz'):\n",
    "            os.remove(path+file)   \n",
    "        else:\n",
    "            print('All files have been Removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Dataset to Numpy Array\n",
    "\n",
    "- First check inside the for loop if the files end with ubyte (These are the files that i extracted earlier)\n",
    "- If the file does match then proceed with opening the file:\n",
    "    - read the file and get the magic number which is 4 bytes\n",
    "    - Also read the size of the images \n",
    "    \n",
    "- Then check if the file image size is 10,000 or 60,000: \n",
    "    - if its 10,000 then its a test image/label file\n",
    "    - if its 60,000 then its Train image/label.\n",
    "  \n",
    "- Check if the magic number is 2051 or 2049:\n",
    "    - If the magic number is 2051 then we know the file is a either train images or test images\n",
    "        - Get the rows and cols from the dataset \n",
    "        - read values as ints and start from 16 as pixels being from byte 16\n",
    "        - Then the int array to reshape(size,rows,cols)\n",
    "    - If the magic number is 2049 then we know the file is eithe train or test labels.\n",
    "        - read values as ints \n",
    "        - reshape int array to reshape(size)\n",
    "        \n",
    "- Lastly add all the values to the array:\n",
    "    - ndArray[trainOrTest+'_'+imgOrLAbel] = parsed\n",
    "    - The files go one by one and its goes through the if statements and the adds it to the array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveToArray():\n",
    "    # This here shows how many files exist in the directory\n",
    "    # It should have 4 different files in the folder \n",
    "    # get a list of all the files in the folder 'data/data'\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    #go through a loop and add the files to the ndarray\n",
    "    for file in files:\n",
    "        #if the extracted file matches then proceed\n",
    "        if file.endswith('ubyte'):\n",
    "            #print('Reading the file', file)\n",
    "            #open the file if the it ends with ubyte and read \n",
    "            with open (path+file,'rb') as f:\n",
    "                #read the file \n",
    "                data = f.read() \n",
    "                # find out the magic number of the file\n",
    "                magic = int.from_bytes(data[0:4], byteorder='big')\n",
    "                # find out the size of the images \n",
    "                size = int.from_bytes(data[4:8], byteorder='big')\n",
    "                \n",
    "                # this is the size of Test images and labels \n",
    "                if (size==10000):\n",
    "                    #here we will know if the file is a test image/label \n",
    "                    trainOrTest = 'test'\n",
    "                # this is the size for training labels and images \n",
    "                elif (size == 60000):\n",
    "                    #here we will know if the file is a Training image/label \n",
    "                    trainOrTest = 'train'\n",
    "                # This checks the magic number 2051 which is for image files \n",
    "                if (magic == 2051):\n",
    "                    imgOrLAbel = 'images'\n",
    "                    #This gets the nummber of rows \n",
    "                    rows = int.from_bytes(data[8:12], byteorder='big')\n",
    "                    #this gets the number of columns \n",
    "                    cols = int.from_bytes(data[12:16], byteorder='big')\n",
    "                    # read values as ints # start from 16 as pixels being from byte 16\n",
    "                    parsed = np.frombuffer(data,dtype = np.uint8, offset = 16) \n",
    "                    # we will reshape the length, 28 x 28 \n",
    "                    parsed = parsed.reshape(size,rows,cols)  \n",
    "                # this checks the magic number 2049 which is for labels \n",
    "                elif (magic == 2049):\n",
    "                    imgOrLAbel = 'labels'\n",
    "                    # read values as ints\n",
    "                    parsed = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "                    #reshape \n",
    "                    parsed = parsed.reshape(size)\n",
    "                #save each file as a array with their key \n",
    "                ndArray[trainOrTest+'_'+imgOrLAbel] = parsed\n",
    "        else:\n",
    "            print('No File Found')\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a method that calls the download function and also the save the MNIST data to array function\n",
    "It checks if the files are already downloaded or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No File Found\n",
      "No File Found\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def checkifFilesExist():\n",
    "    files = os.listdir(path)\n",
    "    counter = 0\n",
    "    #check how many files end with ubyte \n",
    "    for file in files:\n",
    "        if file.endswith('ubyte'):\n",
    "            counter = counter + 1\n",
    "           # saveToArray()\n",
    "    #if it is equal to 4\n",
    "    if counter == 4:\n",
    "        #then save it to array dont need to download it\n",
    "        saveToArray()\n",
    "    else:\n",
    "        DownloadFiles()\n",
    "        saveToArray()\n",
    "        \n",
    "checkifFilesExist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### While Loop for Testing the MNIST Array and Images I Made\n",
    "\n",
    "This is the while loop that tests my saved model which is in the models folder. \n",
    "- I give 3 options to the user \n",
    "- First option asks the user to test the model against the MNIST dataset testing images\n",
    "- Second option test my own images i created \n",
    "- The last option exists out of the while loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    1.Test image from MNIST DataSet Test Images\n",
      "    2.Test a Image file(png)\n",
      "    3.Exit/Quit\n",
      "    \n",
      "What would you like to do? 1\n",
      "\n",
      "Enter a Image number between 0 to 9999 from Mnist Test Images\n",
      "908\n",
      "The Label of the image is:  4\n",
      "The program predicts image number to be: [4]\n",
      "\n",
      "    1.Test image from MNIST DataSet Test Images\n",
      "    2.Test a Image file(png)\n",
      "    3.Exit/Quit\n",
      "    \n",
      "What would you like to do? 2\n",
      "\n",
      " Enter image file (0 to 9 just the number)\n",
      "6\n",
      "\n",
      "The label of the Image is 6\n",
      "The program predicts image number to be: [6]\n",
      "\n",
      "    1.Test image from MNIST DataSet Test Images\n",
      "    2.Test a Image file(png)\n",
      "    3.Exit/Quit\n",
      "    \n",
      "What would you like to do? 3\n",
      "\n",
      " Goodbye\n"
     ]
    }
   ],
   "source": [
    "choice = True\n",
    "while choice:\n",
    "    print(\"\"\"\n",
    "    1.Test image from MNIST DataSet Test Images\n",
    "    2.Test a Image file(png)\n",
    "    3.Exit/Quit\n",
    "    \"\"\")\n",
    "    choice = input(\"What would you like to do? \")\n",
    "\n",
    "    if choice==\"1\":\n",
    "        print(\"\\nEnter a Image number between 0 to 9999 from Mnist Test Images\")\n",
    "        unserInput = input()\n",
    "\n",
    "        print('The Label of the image is: ', ndArray['test_labels'][int(unserInput)]) # it has the same label as the image \n",
    "        # This prints out the first image # int(unserInput) = unser input \n",
    "        # find the unserInput image from the ndArray \n",
    "        image = ndArray['test_images'][int(unserInput),:,:]\n",
    "        # reshapes the image for prediction\n",
    "        image = image.reshape(1,28,28,1)\n",
    "        # Predicting the Test set results\n",
    "        pred = model.predict(image)\n",
    "        correct_indices = np.nonzero(pred)\n",
    "        print(\"The program predicts image number to be:\", correct_indices[-1])\n",
    "        \n",
    "    elif choice==\"2\":\n",
    "        # I made the images in gimp 100px * 100px \n",
    "        # the background needs to be black and the number in white \n",
    "        # if not it wil not work\n",
    "        print(\"\\n Enter image file (0 to 9 just the number)\")\n",
    "        unserInput = input()\n",
    "\n",
    "        # the label is the name of the image in this case \n",
    "        print(\"\\nThe label of the Image is\", unserInput)\n",
    "        #here the image is converted to grayscale and then numpy array\n",
    "        img = Image.open('images/' + unserInput + '.png').convert(\"L\")\n",
    "        img = img.resize((28,28))\n",
    "        im2arr = np.array(img)\n",
    "        im2arr = im2arr.reshape(1,28,28,1)\n",
    "        \n",
    "        # Predicting the Test set results\n",
    "        pred = model.predict(im2arr)\n",
    "        correct_indices = np.nonzero(pred)\n",
    "        print(\"The program predicts image number to be:\", correct_indices[-1])\n",
    "\n",
    "    elif choice==\"3\":\n",
    "        print(\"\\n Goodbye\") \n",
    "        choice = None\n",
    "    else:\n",
    "        print(\"\\n Not Valid Choice Try again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "[Warnings](https://stackoverflow.com/questions/48340392/futurewarning-conversion-of-the-second-argument-of-issubdtype-from-float-to)<br/>\n",
    "[Reshaping of data?](https://datascience.stackexchange.com/questions/11704/reshaping-of-data-for-deep-learning-using-keras)<br/>\n",
    "[Keras sequential](https://keras.io/models/sequential/)<br/>\n",
    "[kerasC](https://anaconda.org/conda-forge/kerasC)<br/>\n",
    "[tutorial](https://elitedatascience.com/keras-tutorial-deep-learning-in-python)<br/>\n",
    "[reshaping-of-data-for-deep-learning-using-keras](https://datascience.stackexchange.com/questions/11704/reshaping-of-data-for-deep-learning-using-keras)<br/>\n",
    "[Keras Model](https://keras.io/layers/core/)<br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
