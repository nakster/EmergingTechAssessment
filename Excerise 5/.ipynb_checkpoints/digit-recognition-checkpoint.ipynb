{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Image Classification With MNIST Dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.simplicity.be/articles/recognizing-handwritten-digits/img/mnist.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "# When the script is run on the computer you need to download keras with anaconda \n",
    "# copy and paste this line in the terminal \n",
    "# conda install -c conda-forge keras \n",
    "# import warnings for unwanted warnings \n",
    "# These are all the imports that are needed \n",
    "from keras.datasets import mnist # dataset\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "# X_train = training images \n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape # this prints out the shape of the training images \n",
    "\n",
    "# These are dimensions of the array [60000,23,28]\n",
    "# print(X_train.shape[0])#number of images \n",
    "# print(X_train.shape[1])#width\n",
    "# print(X_train.shape[2])#height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why reshape ?\n",
    "When the Data is loaded from mnist.load_data() the structure of the data is (60000,28,28) i.e images with 2 dimensions 28 x 28. \n",
    "\n",
    "The Convolution2D layers in Keras work with 4 dimensions (sample/batch, height, width, channels) i.e has 4 dimensions input and output but more importantly, it covers deeper layers of the network, where each example has become a set of feature maps i.e. (nb_samples, nb_features, width, height)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to format which CNN expects (batch, height, width, channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\" or \"transformation\"\n",
    "\n",
    "Each value is between 0-255 in the MNIST Dataset images. However, this would produce math range errors, So all value are divided by 255 to get decimal values between 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train/=255\n",
    "X_test/=255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "\n",
    "One-hot encoding means writing categorical variables in a one-hot vector format, where the vector is all-zero apart from one element. \n",
    "* For example if we are expecting output of 8 so according to one-hot coding its [0,0,0,0,0,0,0,0,1,0]\n",
    "* The index with a non zero value dictates which image label it is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "#number of classes\n",
    "classes = 10\n",
    "# one-hot encoding\n",
    "# we are expecting output as 8 means value of output variable 8\n",
    "# so according to one-hot coding its [0,0,0,0,0,0,0,0,1,0]\n",
    "y_train = np_utils.to_categorical(y_train, classes)\n",
    "y_test = np_utils.to_categorical(y_test, classes)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create A Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "# 32 = convolution filters to use, 5 =rows in each convolution kernel,\n",
    "# and 5 = columns in each convolution kernel\n",
    "# input_shape = (depth, width, height)\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model\n",
    "Now that the model is in place we configure the learning process using .compile()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model \n",
    "To fit the model, all we have to do is declare the batch size and number of epochs to train for, then pass in our training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 1556s 26ms/step - loss: 0.2914 - acc: 0.9125 - val_loss: 0.0623 - val_acc: 0.9819\n"
     ]
    }
   ],
   "source": [
    "# fit the model # im only doing 1 epoch because the time it takes to run 10 epochs is 5 to 6 hours \n",
    "# but i have ran it for 10 epochs and saved the data in h5 file \n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1, batch_size=200)\n",
    "# Save the model to use test the pictures for later\n",
    "model.save('models/mnistModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics(Test loss & Test Accuracy): \n",
      "Test loss: 0.06232676963200793\n",
      "Test accuracy: 0.9819\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "score  = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Metrics(Test loss & Test Accuracy): \")\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "[Warnings](https://stackoverflow.com/questions/48340392/futurewarning-conversion-of-the-second-argument-of-issubdtype-from-float-to)<br/>\n",
    "[Reshaping of data?](https://datascience.stackexchange.com/questions/11704/reshaping-of-data-for-deep-learning-using-keras)<br/>\n",
    "[Keras sequential](https://keras.io/models/sequential/)<br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
